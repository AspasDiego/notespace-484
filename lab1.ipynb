{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f592759",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "Install Modin with Ray backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "befbf2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Modin with Ray backend\n",
    "%pip install -q modin[ray] pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766a8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.3\n",
      "Modin importted suggessfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Modin importted suggessfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff8810",
   "metadata": {},
   "source": [
    "## Basic Operations with Modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7450c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas Dataframe: (1000000, 20)\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 11:23:05,910\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2026-01-30 11:23:11,906\tINFO worker.py:2007 -- Started a local Ray instance.\n",
      "2026-01-30 11:23:16,420\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin Dataframe: (1000000, 20)\n",
      "Type: <class 'modin.pandas.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Create Sample Data\n",
    "np.random.seed(42)\n",
    "n_rows = 1000000\n",
    "n_cols = 20\n",
    "\n",
    "data = np.random.randn(n_rows, n_cols)\n",
    "columns = [f\"col_{i}\" for i in range(n_cols)]\n",
    "\n",
    "# Create Pandas DataFrame\n",
    "pdf = pd.DataFrame(data, columns=columns)\n",
    "print(f\"pandas Dataframe: {pdf.shape}\")\n",
    "print(f\"Type: {type(pdf)}\")\n",
    "\n",
    "# Create Modin DataFrame\n",
    "mdf = mpd.DataFrame(data, columns=columns)\n",
    "print(f\"Modin Dataframe: {mdf.shape}\")\n",
    "print(f\"Type: {type(mdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90e96c",
   "metadata": {},
   "source": [
    "## Verifying API Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ce5505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing pandas and Modin results:\n",
      "\n",
      "Mean of col_0:\n",
      "Pandas: -0.0003920755\n",
      "Modin: -0.0003920755\n",
      "\n",
      "Sum of col_1:\n",
      "Pandas: 623.7120710839\n",
      "Modin: 623.7120710839\n",
      "\n",
      "Standard Deviation of col_2:\n",
      "Pandas: 0.9990888287\n",
      "Modin: 0.9990888287\n",
      "\n",
      "Results are identical!\n",
      "Additional operations:\n",
      "\n",
      "Filtered rows (col_0 > 0):\n",
      " pandas: 499599\n",
      "Modin: 499599\n",
      "\n",
      "First value after sorting:\n",
      " pandas: -4.705028\n",
      " modin: -4.705028\n",
      "\n",
      "GroupBy mean (group A, col_0):\n",
      " pandas: -0.001595\n",
      " modin: -0.002744\n"
     ]
    }
   ],
   "source": [
    "# Verify that operations are identical\n",
    "print(\"Comparing pandas and Modin results:\\n\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Mean of col_0:\")\n",
    "print(f\"Pandas: {pdf['col_0'].mean():.10f}\")\n",
    "print(f\"Modin: {mdf['col_0'].mean():.10f}\")\n",
    "\n",
    "print(\"\\nSum of col_1:\")\n",
    "print(f\"Pandas: {pdf['col_1'].sum():.10f}\")\n",
    "print(f\"Modin: {mdf['col_1'].sum():.10f}\")\n",
    "\n",
    "print(\"\\nStandard Deviation of col_2:\")\n",
    "print(f\"Pandas: {pdf['col_2'].std():.10f}\")\n",
    "print(f\"Modin: {mdf['col_2'].std():.10f}\")\n",
    "\n",
    "print(\"\\nResults are identical!\")\n",
    "\n",
    "# More Operations \n",
    "print(\"Additional operations:\\n\")\n",
    "\n",
    "#Filtering\n",
    "pdf_filtered = pdf[pdf['col_0'] > 0]\n",
    "mdf_filtered = mdf[mdf['col_0'] > 0]\n",
    "print(f\"Filtered rows (col_0 > 0):\")\n",
    "print(f\" pandas: {len(pdf_filtered):}\")\n",
    "print(f\"Modin: {len(mdf_filtered):}\")\n",
    "\n",
    "# Sorting\n",
    "pdf_sorted = pdf.sort_values('col_0')\n",
    "mdf_sorted = mdf.sort_values('col_0')\n",
    "print(f\"\\nFirst value after sorting:\")\n",
    "print(f\" pandas: {pdf_sorted['col_0'].iloc[0]:.6f}\")\n",
    "print(f\" modin: {mdf_sorted['col_0'].iloc[0]:.6f}\")\n",
    "\n",
    "# GroupBy\n",
    "pdf['group'] = np.random.choice(['A', 'B', 'C'], len(pdf))\n",
    "mdf['group'] = np.random.choice(['A', 'B', 'C'], len(mdf))\n",
    "print(\"\\nGroupBy mean (group A, col_0):\")\n",
    "print(f\" pandas: {pdf.groupby('group')['col_0'].mean()['A']:.6f}\")\n",
    "print(f\" modin: {mdf.groupby('group')['col_0'].mean()['A']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db12c3",
   "metadata": {},
   "source": [
    "## Performance Comparison with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a4b125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrames with 2000000 rows and 20 columns...\n",
      "This may take a while...\n",
      "DataFrames created:  2000000 rows x 21 columns\n",
      "\n",
      "==================================================\n",
      "PERFORMANCE BENCHMARKS\n",
      "==================================================\n",
      "\n",
      "Column-wise mean (all columns):\n",
      " pandas: 0.1323 seconds\n",
      " Modin: 0.0258 seconds\n",
      " Speedup: 5.12x\n",
      "\n",
      "Row-wise sum:\n",
      " pandas: 0.3542 seconds\n",
      " Modin: 0.0566 seconds\n",
      " Speedup: 6.26x\n",
      "\n",
      "Boolean filtering (col_0 > 0):\n",
      " pandas: 0.3130 seconds\n",
      " Modin: 0.0487 seconds\n",
      " Speedup: 6.43x\n",
      "\n",
      "GroupBy mean (category):\n",
      " pandas: 0.2653 seconds\n",
      " Modin: 0.0485 seconds\n",
      " Speedup: 5.47x\n",
      "\n",
      "Sorting by col:\n",
      " pandas: 0.8981 seconds\n",
      " Modin: 0.6470 seconds\n",
      " Speedup: 1.39x\n",
      "\n",
      "Apply function (square values):\n",
      " pandas: 0.9217 seconds\n",
      " Modin: 0.2341 seconds\n",
      " Speedup: 3.94x\n",
      "\n",
      "GroupBy with multiple aggregations:\n",
      " pandas: 0.2982 seconds\n",
      " Modin: 0.5193 seconds\n",
      " Speedup: 0.57x\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.29824113845825195, 0.519294023513794)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def benchmark(func, name, n_runs=3):\n",
    "    \"\"\"Run function multiple times.\"\"\"\n",
    "    times = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        result = func()\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    return avg_time\n",
    "\n",
    "\n",
    "def compare_performance(pandas_func, modin_func, operation_name, n_runs=3):\n",
    "    \"\"\"Compare pandas and Modin performance\"\"\"\n",
    "    pandas_time = benchmark(pandas_func, \"pandas\", n_runs)\n",
    "    modin_time = benchmark(modin_func, \"modin\", n_runs)\n",
    "    speedup = pandas_time / modin_time if modin_time > 0 else float('inf')\n",
    "\n",
    "    print(f\"{operation_name}:\")\n",
    "    print(f\" pandas: {pandas_time:.4f} seconds\")\n",
    "    print(f\" Modin: {modin_time:.4f} seconds\")\n",
    "    print(f\" Speedup: {speedup:.2f}x\")\n",
    "    print()\n",
    "\n",
    "    return pandas_time, modin_time\n",
    "\n",
    "# Create larger DataFrames for meaningful benchmarks\n",
    "np.random.seed(42)\n",
    "n_rows = 2000000\n",
    "n_cols = 20\n",
    "\n",
    "print(f\"Creating DataFrames with {n_rows:} rows and {n_cols} columns...\")\n",
    "print(\"This may take a while...\")\n",
    "\n",
    "data = np.random.randn(n_rows, n_cols)\n",
    "columns = [f\"col_{i}\" for i in range(n_cols)]\n",
    "pdf_bench = pd.DataFrame(data, columns=columns)\n",
    "mdf_bench = mpd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Add categorical column for groupby tests\n",
    "categories = np.random.choice(['A', 'B', 'C', 'D', 'E'], n_rows)\n",
    "pdf_bench['category'] = categories\n",
    "mdf_bench['category'] = categories\n",
    "\n",
    "print(f\"DataFrames created: {n_rows: } rows x {n_cols + 1} columns\\n\")\n",
    "print(\"=\"*50)\n",
    "print(\"PERFORMANCE BENCHMARKS\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Benchmark 1: Column Statistics\n",
    "compare_performance(\n",
    "    lambda: pdf_bench.mean(numeric_only=True),\n",
    "    lambda: mdf_bench.mean(numeric_only=True),\n",
    "    \"Column-wise mean (all columns)\"\n",
    ")\n",
    "\n",
    "# Benchmark 2: Row-wise Operations\n",
    "compare_performance(\n",
    "    lambda: pdf_bench.mean(axis=1, numeric_only=True),\n",
    "    lambda: mdf_bench.mean(axis=1, numeric_only=True),\n",
    "    \"Row-wise sum\"\n",
    ")\n",
    "\n",
    "# Benchmark 3: Boolean Filtering\n",
    "compare_performance(\n",
    "    lambda: pdf_bench[pdf_bench['col_0'] > 0],\n",
    "    lambda: mdf_bench[mdf_bench['col_0'] > 0],\n",
    "    \"Boolean filtering (col_0 > 0)\"\n",
    ")\n",
    "\n",
    "# Benchmark 4: GroupBy Aggregation\n",
    "compare_performance(\n",
    "    lambda: pdf_bench.groupby('category').mean(),\n",
    "    lambda: mdf_bench.groupby('category').mean(),\n",
    "    \"GroupBy mean (category)\"\n",
    ")\n",
    "\n",
    "# Benchmark 5: Sorting\n",
    "compare_performance(\n",
    "    lambda: pdf_bench.sort_values('col_0'),\n",
    "    lambda: mdf_bench.sort_values('col_0'),\n",
    "    \"Sorting by col\"\n",
    ")\n",
    "\n",
    "# Benchmark 6: Apply Function\n",
    "compare_performance(\n",
    "    lambda: pdf_bench['col_0'].apply(lambda x: x**2),\n",
    "    lambda: mdf_bench['col_0'].apply(lambda x: x**2),\n",
    "    \"Apply function (square values)\"\n",
    ")\n",
    "\n",
    "# Benchmark 7: Multiple Aggregations\n",
    "compare_performance(\n",
    "    lambda: pdf_bench.groupby('category').agg({'col_0': 'mean', 'col_1': 'sum', 'col_2': 'std'}),\n",
    "    lambda: mdf_bench.groupby('category').agg({'col_0': 'mean', 'col_1': 'sum', 'col_2': 'std'}),\n",
    "    \"GroupBy with multiple aggregations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b8d2a",
   "metadata": {},
   "source": [
    "# Exercise 1: Basic Modin Operations\n",
    "Practice using Modin with basic DataFrame operations.\n",
    "\n",
    "### Task 1.1\n",
    "Create a Modin DataFrame with 500,000 rows and 10 columns of random data. Then:\n",
    "- Calculate the mean and standard deviation of each column\n",
    "- Filter rows where the first column is between -1 and 1\n",
    "- Add a new column that is the sum of the first three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d6f7c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "col_0   -0.000412\n",
      "col_1    0.002796\n",
      "col_2   -0.004849\n",
      "col_3    0.000956\n",
      "col_4   -0.000384\n",
      "col_5   -0.000680\n",
      "col_6    0.000900\n",
      "col_7   -0.000710\n",
      "col_8    0.000484\n",
      "col_9    0.000085\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of each column:\n",
      "col_0    1.000225\n",
      "col_1    1.000111\n",
      "col_2    1.000334\n",
      "col_3    1.000228\n",
      "col_4    0.999932\n",
      "col_5    1.000973\n",
      "col_6    1.000462\n",
      "col_7    1.000395\n",
      "col_8    0.998399\n",
      "col_9    1.000080\n",
      "dtype: float64\n",
      "\n",
      "Filtered DataFrame:\n",
      "           col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
      "0       0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213   \n",
      "1      -0.463418 -0.465730  0.241962 -1.913280 -1.724918 -0.562288 -1.012831   \n",
      "3      -0.601707  1.852278 -0.013497 -1.057711  0.822545 -1.220844  0.208864   \n",
      "4       0.738467  0.171368 -0.115648 -0.301104 -1.478522 -0.719844 -0.460639   \n",
      "5       0.324084 -0.385082 -0.676922  0.611676  1.031000  0.931280 -0.839218   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "499994  0.082527  0.171742  0.712546 -0.253059 -0.817412 -0.980914  0.595972   \n",
      "499995 -0.454918 -0.475504  0.261641 -0.427437  1.455624 -0.302993 -0.603781   \n",
      "499996  0.017225  0.794514  0.505833 -1.544546  1.978758  1.984509 -0.508912   \n",
      "499998 -0.081911 -1.380011  1.231395  0.684233  0.331664  0.983503 -0.197527   \n",
      "499999 -0.363220  1.065874  0.965194  0.635584 -0.813781  0.335310 -0.361246   \n",
      "\n",
      "           col_7     col_8     col_9  \n",
      "0       0.767435 -0.469474  0.542560  \n",
      "1       0.314247 -0.908024 -1.412304  \n",
      "3      -1.959670 -1.328186  0.196861  \n",
      "4       1.057122  0.343618 -1.763040  \n",
      "5      -0.309212  0.331263  0.975545  \n",
      "...          ...       ...       ...  \n",
      "499994  0.455271 -0.894175 -1.501838  \n",
      "499995  0.243861  0.808998 -0.159331  \n",
      "499996 -0.345282 -0.974483  0.509565  \n",
      "499998 -0.388018 -2.065645  2.223921  \n",
      "499999  0.637298 -1.597314 -1.888663  \n",
      "\n",
      "[341442 rows x 10 columns]\n",
      "\n",
      "DataFrame with new column:\n",
      "           col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
      "0       0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213   \n",
      "1      -0.463418 -0.465730  0.241962 -1.913280 -1.724918 -0.562288 -1.012831   \n",
      "2       1.465649 -0.225776  0.067528 -1.424748 -0.544383  0.110923 -1.150994   \n",
      "3      -0.601707  1.852278 -0.013497 -1.057711  0.822545 -1.220844  0.208864   \n",
      "4       0.738467  0.171368 -0.115648 -0.301104 -1.478522 -0.719844 -0.460639   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "499995 -0.454918 -0.475504  0.261641 -0.427437  1.455624 -0.302993 -0.603781   \n",
      "499996  0.017225  0.794514  0.505833 -1.544546  1.978758  1.984509 -0.508912   \n",
      "499997  2.002652  0.753658 -1.110101 -0.000993 -0.771991  0.095725  1.201461   \n",
      "499998 -0.081911 -1.380011  1.231395  0.684233  0.331664  0.983503 -0.197527   \n",
      "499999 -0.363220  1.065874  0.965194  0.635584 -0.813781  0.335310 -0.361246   \n",
      "\n",
      "           col_7     col_8     col_9  sum_first_three  \n",
      "0       0.767435 -0.469474  0.542560         1.006138  \n",
      "1       0.314247 -0.908024 -1.412304        -0.687185  \n",
      "2       0.375698 -0.600639 -0.291694         1.307401  \n",
      "3      -1.959670 -1.328186  0.196861         1.237074  \n",
      "4       1.057122  0.343618 -1.763040         0.794187  \n",
      "...          ...       ...       ...              ...  \n",
      "499995  0.243861  0.808998 -0.159331        -0.668781  \n",
      "499996 -0.345282 -0.974483  0.509565         1.317572  \n",
      "499997 -0.944872 -1.576035 -0.313054         1.646209  \n",
      "499998 -0.388018 -2.065645  2.223921        -0.230528  \n",
      "499999  0.637298 -1.597314 -1.888663         1.667849  \n",
      "\n",
      "[500000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create Modin DataFrame with 500,000 rows and 10 columns of random data\n",
    "np.random.seed(42)\n",
    "n_rows = 500000\n",
    "n_cols = 10\n",
    "data = np.random.randn(n_rows, n_cols)\n",
    "columns = [f\"col_{i}\" for i in range(n_cols)]\n",
    "mdf = mpd.DataFrame(data, columns=columns)\n",
    "\n",
    "#Calculate Mean\n",
    "mean_values = mdf.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(mean_values)\n",
    "\n",
    "# Calculate Standard Deviation\n",
    "std_values = mdf.std()\n",
    "print(\"\\nStandard Deviation of each column:\")\n",
    "print(std_values)\n",
    "\n",
    "# Filter rows where the first column is between -1 and 1\n",
    "filtered_df = mdf[(mdf['col_0'] > -1) & (mdf['col_0'] < 1)]\n",
    "print(\"\\nFiltered DataFrame:\")\n",
    "print(filtered_df)\n",
    "\n",
    "# New column with sum of first three columns\n",
    "mdf['sum_first_three'] = mdf[mdf.columns[:3]].sum(axis=1)\n",
    "print(\"\\nDataFrame with new column:\")\n",
    "print(mdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae90f5d",
   "metadata": {},
   "source": [
    "## Working with Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03f0b9",
   "metadata": {},
   "source": [
    "### Download NYC Taxi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7806b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File yellow_tripdata_2023-01.parquet already exists.\n"
     ]
    }
   ],
   "source": [
    "# NYC Taxi Dataset\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\" \n",
    "filename = \"yellow_tripdata_2023-01.parquet\"\n",
    "\n",
    "# Download the dataset\n",
    "if not os.path.exists(filename):\n",
    "    print(f\"Downloading NYC Taxi data from TLC website...\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "else:\n",
    "    print(f\"File {filename} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b8a66",
   "metadata": {},
   "source": [
    "### Reading Large File: Pandas vs Modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b041c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Benchmark: Reading file\n",
      "==================================================\n",
      "\n",
      " pandas read_time: 2.26 seconds\n",
      " Shape: (3066766, 19)\n",
      " Memory: 588.46 MB\n",
      " Modin read_time: 1.67 seconds\n",
      " Shape: (3066766, 19)\n",
      " Memory: 588.46 MB\n",
      " \n",
      "Speedup: 1.35x\n",
      "Dataset columns:\n",
      "['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "\n",
      "Dataset info:\n",
      " Records: 3,066,766\n",
      " Speedup: 1.35x\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-30 11:23:41,513 E 38260 33632] (gcs_server.exe) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3   1.00      0.5        0.00           0.0   \n",
       "1             1          7.9   1.00      0.5        4.00           0.0   \n",
       "2             1         14.9   1.00      0.5       15.00           0.0   \n",
       "3             1         12.1   7.25      0.5        0.00           0.0   \n",
       "4             1         11.4   1.00      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         14.30                   2.5         0.00  \n",
       "1                    1.0         16.90                   2.5         0.00  \n",
       "2                    1.0         34.90                   2.5         0.00  \n",
       "3                    1.0         20.85                   0.0         1.25  \n",
       "4                    1.0         19.68                   2.5         0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Benchmark: Reading file\n",
    "print(\"=\"*50)\n",
    "print(\"Benchmark: Reading file\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Pandas read\n",
    "start = time.time()\n",
    "pdf_taxi = pd.read_parquet(filename)\n",
    "pandas_read_time = time.time() - start\n",
    "print(f\" pandas read_time: {pandas_read_time:.2f} seconds\")\n",
    "print(f\" Shape: {pdf_taxi.shape}\")\n",
    "print(f\" Memory: {pdf_taxi.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Modin read\n",
    "start = time.time()\n",
    "mdf_taxi = mpd.read_parquet(filename)\n",
    "modin_read_time = time.time() - start\n",
    "print(f\" Modin read_time: {modin_read_time:.2f} seconds\")\n",
    "print(f\" Shape: {mdf_taxi.shape}\")\n",
    "print(f\" Memory: {mdf_taxi.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\" \\nSpeedup: {pandas_read_time / modin_read_time:.2f}x\")\n",
    "\n",
    "# View the data structure\n",
    "print(\"Dataset columns:\")\n",
    "print(mdf_taxi.columns.tolist())\n",
    "print(f\"\\nDataset info:\")\n",
    "print(f\" Records: {len(mdf_taxi):,}\")\n",
    "print(f\" Speedup: {pandas_read_time / modin_read_time:.2f}x\\n\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"First few rows:\")\n",
    "mdf_taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9921dc",
   "metadata": {},
   "source": [
    "### CSV Version for Additional Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a3b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file size: 309.97 MB\n",
      "==================================================\n",
      "Benchmark: Reading CSV File\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2026-01-30 11:23:44,113 E 40708 33388] (raylet.exe) main.cc:1032: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pandas read_time: 9.56 seconds\n",
      " Modin read_time: 3.08 seconds\n",
      " \n",
      "Speedup: 3.10x\n"
     ]
    }
   ],
   "source": [
    "# Save as CSV for benchmarking\n",
    "csv_filename = \"taxi_data.csv\"\n",
    "\n",
    "if not os.path.exists(csv_filename):\n",
    "    print(f\"Creating CSV file for benchmarking...\")\n",
    "    pdf_taxi.to_csv(csv_filename, index=False)\n",
    "    print(f\"Created: {csv_filename}\")\n",
    "\n",
    "print(f\"CSV file size: {os.path.getsize(csv_filename) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Benchmark: Reading CSV files\n",
    "print(\"=\"*50)\n",
    "print(\"Benchmark: Reading CSV File\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Pandas read\n",
    "start = time.time()\n",
    "pdf_csv = pd.read_csv(csv_filename)\n",
    "pandas_csv_time = time.time() - start\n",
    "print(f\" pandas read_time: {pandas_csv_time:.2f} seconds\")\n",
    "\n",
    "# Modin read\n",
    "start = time.time()\n",
    "mdf_csv = mpd.read_csv(csv_filename)\n",
    "modin_csv_time = time.time() - start\n",
    "print(f\" Modin read_time: {modin_csv_time:.2f} seconds\")\n",
    "\n",
    "print(f\" \\nSpeedup: {pandas_csv_time / modin_csv_time:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d52916",
   "metadata": {},
   "source": [
    "### Loading Multiple Months of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09595ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " yellow_tripdata_2023-01.parquet already exists (45.46 MB)\n",
      " yellow_tripdata_2023-02.parquet already exists (45.54 MB)\n",
      "\n",
      "Total parquet files: 2\n",
      "Total size: 91.00 MB\n",
      "Loading and combining all months with Modin...\n",
      "Load time: 7.06 seconds\n",
      "\n",
      "Combined dataset:\n",
      " Records: 5,980,721\n",
      " Columns: 20\n"
     ]
    }
   ],
   "source": [
    "months = ['2023-01', '2023-02']\n",
    "base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{}.parquet\"\n",
    "\n",
    "parquet_files = []\n",
    "total_size = 0\n",
    "\n",
    "for month in months:\n",
    "    filename = f\"yellow_tripdata_{month}.parquet\"\n",
    "    parquet_files.append(filename)\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        url = base_url.format(month)\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        size_mb = os.path.getsize(filename) / 1024**2\n",
    "        print(f\" Downloaded: {size_mb:.2f} MB\")\n",
    "        total_size += size_mb\n",
    "    else:\n",
    "        size_mb = os.path.getsize(filename) / 1024**2\n",
    "        print(f\" {filename} already exists ({size_mb:.2f} MB)\")\n",
    "        total_size += size_mb\n",
    "\n",
    "print(f\"\\nTotal parquet files: {len(parquet_files)}\")\n",
    "print(f\"Total size: {total_size:.2f} MB\")\n",
    "\n",
    "# Load and combine all months with Modin\n",
    "print(\"Loading and combining all months with Modin...\")\n",
    "start = time.time()\n",
    "\n",
    "dfs = [mpd.read_parquet(f) for f in parquet_files]\n",
    "mdf_combined = mpd.concat(dfs, ignore_index=True)\n",
    "\n",
    "load_time = time.time() - start\n",
    "print(f\"Load time: {load_time:.2f} seconds\")\n",
    "print(f\"\\nCombined dataset:\")\n",
    "print(f\" Records: {len(mdf_combined):,}\")\n",
    "print(f\" Columns: {len(mdf_combined.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33f939",
   "metadata": {},
   "source": [
    "### Converting Between Modin and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf93130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Modin to pandas...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion time: 1.48 seconds\n",
      "Result type: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Converting pandas to Modin...\n",
      "Conversion time: 5.18 seconds\n",
      "Result type: <class 'modin.pandas.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Convert Modin DataFrame to pandas\n",
    "print(\"Converting Modin to pandas...\")\n",
    "start = time.time()\n",
    "pdf_from_modin = mdf_taxi._to_pandas()\n",
    "convert_time = time.time() - start\n",
    "\n",
    "print(f\"Conversion time: {convert_time:.2f} seconds\")\n",
    "print(f\"Result type: {type(pdf_from_modin)}\")\n",
    "\n",
    "# Convert pandas DataFrame to Modin\n",
    "print(\"\\nConverting pandas to Modin...\")\n",
    "start = time.time()\n",
    "mdf_from_pandas = mpd.DataFrame(pdf_taxi)\n",
    "convert_time = time.time() - start\n",
    "\n",
    "print(f\"Conversion time: {convert_time:.2f} seconds\")\n",
    "print(f\"Result type: {type(mdf_from_pandas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3a121",
   "metadata": {},
   "source": [
    "## Execise 2\n",
    "\n",
    "### Task 2.1\n",
    "Using the combined taxi dataset (mdf_combined):\n",
    "- How many total trips are in the dataset?\n",
    "- What is the date range of the data (min and max pickup datetime)?\n",
    "- What percentage of trips have 0 passengers recorded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d80075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trips: VendorID                 5980721\n",
      "tpep_pickup_datetime     5980721\n",
      "tpep_dropoff_datetime    5980721\n",
      "passenger_count          5832161\n",
      "trip_distance            5980721\n",
      "RatecodeID               5832161\n",
      "store_and_fwd_flag       5832161\n",
      "PULocationID             5980721\n",
      "DOLocationID             5980721\n",
      "payment_type             5980721\n",
      "fare_amount              5980721\n",
      "extra                    5980721\n",
      "mta_tax                  5980721\n",
      "tip_amount               5980721\n",
      "tolls_amount             5980721\n",
      "improvement_surcharge    5980721\n",
      "total_amount             5980721\n",
      "congestion_surcharge     5832161\n",
      "airport_fee              2995023\n",
      "Airport_fee              2837138\n",
      "dtype: int64 \n",
      "\n",
      "Pickup date range: 2008-12-31 23:01:42 to 2023-03-07 13:01:28\n",
      "Percentage of trips with 0 passengers: 1.6459721160709553\n"
     ]
    }
   ],
   "source": [
    "#Total Number of Trips\n",
    "total_trips = mdf_combined.count()\n",
    "print(f\"Total number of trips: {total_trips} \\n\")\n",
    "\n",
    "# Date Range\n",
    "min_pickup = mdf_combined[\"tpep_pickup_datetime\"].min()\n",
    "max_pickup = mdf_combined[\"tpep_pickup_datetime\"].max()\n",
    "print(f\"Pickup date range: {min_pickup} to {max_pickup}\")\n",
    "\n",
    "# Percentage Trips with 0 Passengers\n",
    "percentage_zero_passengers = (\n",
    "    (mdf_combined[\"passenger_count\"] == 0).mean() * 100\n",
    ")\n",
    "print(\"Percentage of trips with 0 passengers:\", percentage_zero_passengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fce74b",
   "metadata": {},
   "source": [
    "## Advanced Modin Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e00eb",
   "metadata": {},
   "source": [
    "### Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ff8ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "==================================================\n",
      "\n",
      "Total Trips: 3,066,766\n",
      "\n",
      " Fare amount statistics:\n",
      "count    3.066766e+06\n",
      "mean     1.836707e+01\n",
      "std      1.780782e+01\n",
      "min     -9.000000e+02\n",
      "25%      8.600000e+00\n",
      "50%      1.280000e+01\n",
      "75%      2.050000e+01\n",
      "max      1.160100e+03\n",
      "Name: fare_amount, dtype: float64\n",
      "Missing value per column:\n",
      "==================================================\n",
      "                      Missing Count  Missing %\n",
      "passenger_count               71743       2.34\n",
      "RatecodeID                    71743       2.34\n",
      "store_and_fwd_flag            71743       2.34\n",
      "congestion_surcharge          71743       2.34\n",
      "airport_fee                   71743       2.34\n",
      "\n",
      "Cleaning Data...\n",
      "Original records: 3,066,766\n",
      "After cleaning: 2,884,228\n",
      "Removed: 182,538 invalid records\n"
     ]
    }
   ],
   "source": [
    "# Basic Statistics of Dataset\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Using single-month dataset \n",
    "print(f\"\\nTotal Trips: {len(mdf_taxi):,}\")\n",
    "\n",
    "# Numeric Columns Summary\n",
    "print(\"\\n Fare amount statistics:\")\n",
    "fare_stats = mdf_taxi['fare_amount'].describe()\n",
    "print(fare_stats)\n",
    "\n",
    "# Check for Missing Values\n",
    "print(\"Missing value per column:\")\n",
    "print(\"=\"*50)\n",
    "missing = mdf_taxi.isnull().sum()\n",
    "missing_pct = (missing / len(mdf_taxi) * 100).round(2)\n",
    "\n",
    "missing_df = mpd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    \"Missing %\": missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count']>0])\n",
    "\n",
    "# Data Cleaning - Remove Invalid Records\n",
    "print(\"\\nCleaning Data...\")\n",
    "print(f\"Original records: {len(mdf_taxi):,}\")\n",
    "\n",
    "# Filter valid trips\n",
    "mdf_clean = mdf_taxi[\n",
    "    (mdf_taxi['fare_amount'] > 0) &\n",
    "    (mdf_taxi['trip_distance'] > 0) &\n",
    "    (mdf_taxi['passenger_count'] > 0)\n",
    "]\n",
    "\n",
    "print(f\"After cleaning: {len(mdf_clean):,}\")\n",
    "print(f\"Removed: {len(mdf_taxi) - len(mdf_clean):,} invalid records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706342be",
   "metadata": {},
   "source": [
    "### GroupBy and Aggregations at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "059daef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GROUPBY OPERATIONS\n",
      "==================================================\n",
      "\n",
      "1. Average fare by payment type:\n",
      " Time: 1.14s\n",
      "payment_type\n",
      "4    18.849528\n",
      "2    18.572971\n",
      "1    18.543035\n",
      "3    17.436227\n",
      "Name: fare_amount, dtype: float64\n",
      "\n",
      "2. Statistics by vendor:\n",
      " Time: 0.05s\n",
      "         fare_amount                       trip_distance           tip_amount\n",
      "                mean          sum    count          mean       max       mean\n",
      "VendorID                                                                     \n",
      "1          17.462771  12913945.93   739513      3.235839    204.10   3.152932\n",
      "2          18.920187  40578409.09  2144715      3.554463  14098.55   3.485630\n",
      "\n",
      "3. Top 10 pickup locations by trip count:\n",
      " Time: 0.79s\n",
      "PULocationID\n",
      "132    152122\n",
      "237    141109\n",
      "236    130887\n",
      "161    129103\n",
      "186    104813\n",
      "162    100807\n",
      "142     94910\n",
      "230     94226\n",
      "138     86750\n",
      "170     83993\n",
      "Name: count, dtype: int64\n",
      "\n",
      "4. Average fare by top pickup locations:\n",
      " Time: 0.60s\n",
      "PULocationID\n",
      "132    60.738717\n",
      "138    41.487665\n",
      "230    17.378985\n",
      "186    15.554415\n",
      "161    15.258497\n",
      "162    14.895656\n",
      "170    14.845467\n",
      "142    13.600257\n",
      "236    13.126819\n",
      "237    12.354582\n",
      "Name: fare_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# GroupBy operations on large dataset\n",
    "print(\"=\"*50)\n",
    "print(\"GROUPBY OPERATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Average fare by payment type\n",
    "print(\"\\n1. Average fare by payment type:\")\n",
    "start = time.time()\n",
    "fare_by_payment = mdf_clean.groupby('payment_type')['fare_amount'].mean()\n",
    "print(f\" Time: {time.time() - start:.2f}s\")\n",
    "print(fare_by_payment.sort_values(ascending=False))\n",
    "\n",
    "# Multiple Aggregatopms by Vendor\n",
    "print(\"\\n2. Statistics by vendor:\")\n",
    "start = time.time()\n",
    "vendor_stats = mdf_clean.groupby('VendorID').agg({\n",
    "    'fare_amount' : ['mean', 'sum', 'count'],\n",
    "    'trip_distance' : ['mean', 'max'],\n",
    "    'tip_amount' : 'mean'\n",
    "})\n",
    "print(f\" Time: {time.time() - start:.2f}s\")\n",
    "print(vendor_stats)\n",
    "\n",
    "# Top pickup locations\n",
    "print(\"\\n3. Top 10 pickup locations by trip count:\")\n",
    "start = time.time()\n",
    "top_locations = mdf_clean['PULocationID'].value_counts().head(10)\n",
    "print(f\" Time: {time.time() - start:.2f}s\")\n",
    "print(top_locations)\n",
    "\n",
    "# Fare statistics by pickup location(top 10)\n",
    "print(\"\\n4. Average fare by top pickup locations:\")\n",
    "start = time.time()\n",
    "top_location_ids = top_locations.index.tolist()\n",
    "top_loc_fares = mdf_clean[mdf_clean['PULocationID'].isin(top_location_ids)].groupby('PULocationID')['fare_amount'].mean()\n",
    "print(f\" Time: {time.time() - start:.2f}s\")\n",
    "print(top_loc_fares.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5351a",
   "metadata": {},
   "source": [
    "### Data Transformation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7686890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding derived columns...\n",
      "Time: 0.25s\n",
      "\n",
      "New columns added: tip_percentage, fare_per_mile, pickup_hour, pickup_dayofweek, pickup_date\n",
      "\n",
      "Sample of new features:\n",
      "\n",
      "Average fare by hour of day:\n",
      "             fare_amount  trip_distance  tip_percentage\n",
      "pickup_hour                                            \n",
      "0                  19.80           4.03           20.42\n",
      "1                  17.82           3.49           20.95\n",
      "2                  16.72           3.22           20.77\n",
      "3                  17.74           3.51           20.26\n",
      "4                  22.25           4.68           17.97\n",
      "5                  26.46           6.42           16.57\n",
      "6                  22.15           4.78           18.11\n",
      "7                  18.92           3.68           37.65\n",
      "8                  17.43           3.18           20.04\n",
      "9                  17.61           3.09           19.91\n",
      "10                 17.73           3.14           19.52\n",
      "11                 17.41           3.04           19.48\n",
      "12                 17.76           3.11           19.51\n",
      "13                 18.46           3.29           19.38\n",
      "14                 19.76           3.61           19.27\n",
      "15                 19.29           3.75           19.35\n",
      "16                 19.54           3.52           21.79\n",
      "17                 18.63           3.30           21.90\n",
      "18                 16.98           2.94           22.52\n",
      "19                 17.65           3.52           22.40\n",
      "20                 18.03           3.45           22.90\n",
      "21                 18.50           3.61           21.75\n",
      "22                 19.39           3.85           21.16\n",
      "23                 20.59           4.23           20.62\n",
      "\n",
      "Trips by day of week:\n",
      " Monday : 380,400\n",
      " Tuesday : 462,394\n",
      " Wednesday : 392,054\n",
      " Thursday : 415,112\n",
      " Friday : 409,191\n",
      " Saturday : 416,631\n",
      " Sunday : 408,446\n"
     ]
    }
   ],
   "source": [
    "# Add derived columns\n",
    "print('Adding derived columns...')\n",
    "start = time.time()\n",
    "\n",
    "# Make a copy for transformations\n",
    "mdf_features = mdf_clean.copy()\n",
    "\n",
    "# Calculate tip percentage\n",
    "mdf_features['tip_percentage'] = (mdf_features['tip_amount'] / mdf_features['fare_amount'] * 100).round(2)\n",
    "\n",
    "# Calculate fare per mile\n",
    "mdf_features['fare_per_mile'] = (mdf_features['fare_amount'] / mdf_features['trip_distance']).round(2)\n",
    "\n",
    "# Extract datetime components\n",
    "mdf_features['pickup_hour'] = mpd.to_datetime(mdf_features['tpep_pickup_datetime']).dt.hour\n",
    "mdf_features['pickup_dayofweek'] = mpd.to_datetime(mdf_features['tpep_pickup_datetime']).dt.dayofweek\n",
    "mdf_features['pickup_date'] = mpd.to_datetime(mdf_features['tpep_pickup_datetime']).dt.date\n",
    "\n",
    "print(f\"Time: {time.time() - start:.2f}s\")\n",
    "print(\"\\nNew columns added: tip_percentage, fare_per_mile, pickup_hour, pickup_dayofweek, pickup_date\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nSample of new features:\")\n",
    "mdf_features[['fare_amount', 'tip_amount', 'tip_percentage', 'trip_distance', 'fare_per_mile', 'pickup_hour']].head()\n",
    "\n",
    "# Analyse patterns by time\n",
    "print(\"\\nAverage fare by hour of day:\")\n",
    "hourly_stats = mdf_features.groupby('pickup_hour').agg({\n",
    "    'fare_amount': 'mean',\n",
    "    'trip_distance': 'mean',\n",
    "    'tip_percentage': 'mean'\n",
    "}).round(2)\n",
    "print(hourly_stats)\n",
    "\n",
    "# Day of week analysis\n",
    "print(\"\\nTrips by day of week:\")\n",
    "day_names = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "daily_trips = mdf_features['pickup_dayofweek'].value_counts().sort_index()\n",
    "for day, count in daily_trips.items():\n",
    "    print(f\" {day_names[day]} : {count:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32e288",
   "metadata": {},
   "source": [
    "### Applying Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a063d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying custom function to catergorise trips...\n",
      "Time: 0.12s\n",
      "\n",
      "Trip categories:\n",
      "trip_category\n",
      "Short         1462266\n",
      "Very Short     596061\n",
      "Medium         588867\n",
      "Long           237034\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applying lambda function to calculate total cost with tip...\n",
      "Time: 30.96s\n",
      "\n",
      "Total cost statistics:\n",
      "count    2.884228e+06\n",
      "mean     2.247460e+01\n",
      "std      2.100029e+01\n",
      "min      1.000000e-02\n",
      "25%      1.078000e+01\n",
      "50%      1.532000e+01\n",
      "75%      2.390000e+01\n",
      "max      1.166650e+03\n",
      "Name: total_with_tip, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apply custom function to categorise trips\n",
    "def categorize_trip(distance):\n",
    "    if  distance < 1:\n",
    "        return 'Very Short'\n",
    "    elif distance < 3:\n",
    "        return 'Short'\n",
    "    elif distance < 10:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Long'\n",
    "\n",
    "print(\"Applying custom function to catergorise trips...\")\n",
    "start = time.time()\n",
    "mdf_features['trip_category'] = mdf_features['trip_distance'].apply(categorize_trip)\n",
    "print(f\"Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "print(\"\\nTrip categories:\")\n",
    "print(mdf_features['trip_category'].value_counts())\n",
    "\n",
    "# Using apply with lambda functions\n",
    "print(\"\\nApplying lambda function to calculate total cost with tip...\")\n",
    "start = time.time()\n",
    "mdf_features['total_with_tip'] = mdf_features.apply(\n",
    "    lambda row: row['fare_amount'] + row['tip_amount'] + row['tolls_amount'],\n",
    "    axis=1\n",
    ")\n",
    "print(f\"Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "print(\"\\nTotal cost statistics:\")\n",
    "print(mdf_features['total_with_tip'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
